principal_component # it is giving the eigen values and corresponding eigen vector
tooth.paste<-read.csv(file.choose()) #Import the data file into R
tooth.paste
head(tooth.paste)  # To see the few observations from dataset
tooth.paste<-tooth.paste[,-1] #removal of first column form data set
tooth.paste
head(tooth.paste)
# Load the necessary packages to do the factor analysis
library(psych)
library(REdaS)
R<-cor(tooth.paste)  ##for finding the correaltion of the given data matrix
round(R,2) # here we round off variables upto 2 decimals
bart_spher(tooth.paste)#when we have to study population correlation is identical or
#not then we use bartlett test of sphericity
KMOS(tooth.paste) #KMO) test is a measure of sampling adequacy used in factor analysis to assess
principal_component<-prcomp(tooth.paste)
principal_component # it is giving the eigen values and corresponding eigen vector
summary(principal_component) # gives the summary of principal components
##Principle components in loading plots
biplot(prcomp(tooth.paste)) #by using this plot we can find that which variables
screeplot(principal_component,type = "line") # Generation of scree plot
factor.analysis<-factanal(x=tooth.paste,factors=9 ,scores = "Bartlett",rotation = "varimax")
factor.analysis
model=glm(class~Factor1 ,family=binomial(link = "logit"),data=tooth.paste)
model=glm(class~Factor1+Factor2 ,family=binomial(link = "logit"),data=tooth.paste)
model=glm(class~Factor2 ,family=binomial(link = "logit"),data=tooth.paste)
model=glm(class~factor2 ,family=binomial(link = "logit"),data=tooth.paste)
tooth.paste<-read.csv(file.choose()) #Import the data file into R
tooth.paste
head(tooth.paste)  # To see the few observations from dataset
tooth.paste<-tooth.paste[,-1] #removal of first column form data set
tooth.paste
head(tooth.paste)
# Load the necessary packages to do the factor analysis
library(psych)
library(REdaS)
R<-cor(tooth.paste)  ##for finding the correaltion of the given data matrix
round(R,2) # here we round off variables upto 2 decimals
bart_spher(tooth.paste)#when we have to study population correlation is identical or
#not then we use bartlett test of sphericity
KMOS(tooth.paste) #KMO) test is a measure of sampling adequacy used in factor analysis to assess
principal_component<-prcomp(tooth.paste)
principal_component # it is giving the eigen values and corresponding eigen vector
summary(principal_component) # gives the summary of principal components
##Principle components in loading plots
biplot(prcomp(tooth.paste)) #by using this plot we can find that which variables
screeplot(principal_component,type = "line") # Generation of scree plot
factor.analysis<-factanal(x=tooth.paste,factors=9 ,scores = "Bartlett",rotation = "varimax")
factor.analysis
factor.analysis<-factanal(x=tooth.paste,factors=8 ,scores = "Bartlett",rotation = "varimax")
factor.analysis<-factanal(x=tooth.paste,factors=8 ,scores = "Bartlett",rotation = "varimax")
factor.analysis
factor.analysis<-factanal(x=tooth.paste,factors=10 ,scores = "Bartlett",rotation = "varimax")
factor.analysis
factor.analysis<-factanal(x=tooth.paste,factors=8 ,scores = "Bartlett",rotation = "varimax")
factor.analysis
factor.analysis<-factanal(x=tooth.paste,factors=9 ,scores = "Bartlett",rotation = "varimax")
factor.analysis
library(meta)
install.packages("meta")
library(meta)
library(metafor)
# Read in data
data <- read.csv("meta_analysis_data.csv")
# Load the metafor package
library(metafor)
# Create a dataset with effect sizes and standard errors for each study
dat <- data.frame(
study = c("Study 1", "Study 2", "Study 3", "Study 4"),
effect_size = c(0.50, 0.75, 0.25, 0.90),
se = c(0.10, 0.12, 0.08, 0.15)
)
# Create a random-effects model using the 'rma' function
model <- rma(effect_size, se, data = dat, method = "REML")
# Create a forest plot using the 'forest' function
forest(model, slab = dat$study, xlim = c(-1, 2),
ilab = cbind(dat$effect_size, dat$se),
ilab.xpos = c(-0.9, -0.8, -0.7, -0.6),
mlab = "Overall Effect", addfit = TRUE)
# Load the metafor package
library(metafor)
# Load the metafor package
library(metafor)
# Create a dataset with effect sizes and standard errors for each study
dat <- data.frame(
study = c("Study 1", "Study 2", "Study 3", "Study 4"),
effect_size = c(0.50, 0.75, 0.25, 0.90),
se = c(0.10, 0.12, 0.08, 0.15)
)
# Create a random-effects model using the 'rma' function
model <- rma(effect_size, se, data = dat, method = "REML")
# Create a forest plot using the 'forest' function
forest(model, slab = dat$study, xlim = c(-1, 2),
ilab = cbind(dat$effect_size, dat$se),
ilab.xpos = c(-0.9, -0.8, -0.7, -0.6),
mlab = "Overall Effect", addfit = TRUE)
# Create a funnel plot using the 'funnel' function
funnel(model)
# Load the metafor package
library(metafor)
# Create a dataset with effect sizes and standard errors for each study
dat <- data.frame(
study = c("Study 1", "Study 2", "Study 3", "Study 4"),
effect_size = c(0.50, 0.75, 0.25, 0.90),
se = c(0.10, 0.12, 0.08, 0.15)
)
# Create a random-effects model using the 'rma' function
model <- rma(effect_size, se, data = dat, method = "REML")
# Create a forest plot using the 'forest' function
forest(model, slab = dat$study, xlim = c(-1, 2),
ilab = cbind(dat$effect_size, dat$se),
ilab.xpos = c(-0.9, -0.8, -0.7, -0.6),
mlab = "Overall Effect", addfit = TRUE)
# Create a funnel plot using the 'funnel' function
funnel(model)
install.packages(c("survival", "survminer"))
library("survival")
library("survminer")
data("lung")
head(lung)
#inst: Institution code
#time: Survival time in days
#status: censoring status 1=censored, 2=dead
#age: Age in years
#sex: Male=1 Female=2
#ph.ecog: ECOG performance score (0=good 5=dead)
#ph.karno: Karnofsky performance score (bad=0-good=100) rated by physician
#pat.karno: Karnofsky performance score as rated by patient
#meal.cal: Calories consumed at meals
#wt.loss: Weight loss in last six months
res.cox <- coxph(Surv(time, status) ~ sex+age+ph.ecog+ph.karno+pat.karno+meal.cal+wt.loss data = lung)
#inst: Institution code
#time: Survival time in days
#status: censoring status 1=censored, 2=dead
#age: Age in years
#sex: Male=1 Female=2
#ph.ecog: ECOG performance score (0=good 5=dead)
#ph.karno: Karnofsky performance score (bad=0-good=100) rated by physician
#pat.karno: Karnofsky performance score as rated by patient
#meal.cal: Calories consumed at meals
#wt.loss: Weight loss in last six months
res.cox <- coxph(Surv(time, status) ~ sex+age+ph.ecog+ph.karno+pat.karno+meal.cal+wt.loss, data = lung)
res.cox
summary(res.cox)
library("survival")
library("survminer")
data("lung")
head(lung)
#inst: Institution code
#time: Survival time in days
#status: censoring status 1=censored, 2=dead
#age: Age in years
#sex: Male=1 Female=2
#ph.ecog: ECOG performance score (0=good 5=dead)
#ph.karno: Karnofsky performance score (bad=0-good=100) rated by physician
#pat.karno: Karnofsky performance score as rated by patient
#meal.cal: Calories consumed at meals
#wt.loss: Weight loss in last six months
res.cox <- coxph(Surv(time, status) ~ sex+age+ph.ecog+ph.karno+pat.karno+meal.cal+wt.loss, data = lung)
res.cox
summary(res.cox)
#The Cox regression results can be interpreted as follow:
#The Cox regression results can be interpreted as follow:
#Statistical significance. The column marked "z" gives the Wald statistic value.
#The Cox regression results can be interpreted as follow:
#Statistical significance. The column marked "z" gives the Wald statistic value.
#It corresponds to the ratio of each regression coefficient of its standard error (z = coef/se(coef)).
#The Cox regression results can be interpreted as follow:
#Statistical significance. The column marked "z" gives the Wald statistic value.
#It corresponds to the ratio of each regression coefficient of its standard error (z = coef/se(coef)).
#The wald statistic evaluates,whether the beta (??) coefficient of a given variable is statistically significantly different from 0.
#The regression coefficients. The second feature to note in the Cox model results is the the sign of the
install.packages(c("survival", "survminer"))
install.packages(c("survival", "survminer"))
#Practical no 6
n=14
category=c("Filling","crown","Extraction","checkup")
s.time=c(45,60,15,45,15)
ST=vector("numeric")
SC=vector("character")
pi=c(0.4,0.15,0.15,0.1,0.2)
#Practical no 6
n=14
category=c("Filling","crown","Extraction","checkup")
s.time=c(45,60,15,45,15)
ST=vector("numeric")
SC=vector("character")
pi=c(0.4,0.15,0.15,0.1,0.2)
n=14
category=c("filling","crown","Extraction","checkup")
ST=vector("numeric")
SC=vector("character")
pi=c(0.4,0.15,0.15,0.1,0.2)
p=cummin(pi)
p=c(0,p)
i=1
while (i<=n) {
u=runif(1)
print(u)
for (j in 1:length(p))
{
if(u>p[j] && u<p[j+1])
{
ST[i]=s.time[j]
SC[i]=category[j]
}
}
i=i+1
ST
SC
Arrival.time=seq(0,390,30)
Arrival.time
}
#Practical no 6
n=14
category=c("Filling","crown","Extraction","checkup")
s.time=c(45,60,15,45,15)
ST=vector("numeric")
SC=vector("character")
pi=c(0.4,0.15,0.15,0.1,0.2)
n=14
category=c("filling","crown","Extraction","checkup")
ST=vector("numeric")
SC=vector("character")
pi=c(0.4,0.15,0.15,0.1,0.2)
p=cummin(pi)
p=c(0,p)
i=1
while (i<=n) {
u=runif(1)
print(u)
for (j in 1:length(p))
{
if(u>p[j] && u<p[j+1])
{
ST[i]=s.time[j]
SC[i]=category[j]
}
}
i=i+1
}
tooth.paste<-read.csv(file.choose()) #Import the data file into R
tooth.paste<-read.csv(file.choose()) #Import the data file into R
tooth.paste<-read.csv(file.choose()) #Import the data file into R
tooth.paste
head(tooth.paste)  # To see the few observations from dataset
tooth.paste<-tooth.paste[,-1] #removal of first column form data set
tooth.paste
head(tooth.paste)
# Load the necessary packages to do the factor analysis
library(psych)
library(REdaS)
R<-cor(tooth.paste)  ##for finding the correaltion of the given data matrix
round(R,2) # here we round off variables upto 2 decimals
bart_spher(tooth.paste)#when we have to study population correlation is identical or
#not then we use bartlett test of sphericity
KMOS(tooth.paste) #KMO) test is a measure of sampling adequacy used in factor analysis to assess
principal_component<-prcomp(tooth.paste)
principal_component # it is giving the eigen values and corresponding eigen vector
summary(principal_component) # gives the summary of principal components
##Principle components in loading plots
biplot(prcomp(tooth.paste)) #by using this plot we can find that which variables
screeplot(principal_component,type = "line") # Generation of scree plot
factor.analysis0<-factanal(x=tooth.paste,factors =2,scores = "Bartlett",rotation = "none")
factor.analysis0
factor.analysis<-factanal(x=tooth.paste,factors=9 ,scores = "Bartlett",rotation = "varimax")
factor.analysis
data =read.csv( file .choose())
data =read.csv( file.choose())
data
head(data)
data1 =read.csv( file.choose())
data1 =read.csv( file.choose())
data1
head(data)
model= glm(class~ Blood_pressure+ aanemia age + appetite+ bacteria+ blood_glucose_random + coronary_artery_disease + haemoglobin+  packed_cell_volume+ peda_edema+ potassium +pus_cell+ pus_cell_clumps + red_blood_cell_count +red_blood_cells +serum_creatinine+ sodium+ specific_gravity,family=binomial(link="logit"),data=data1)
model= glm(class ~ Blood_pressure+ aanemia age + appetite+ bacteria+ blood_glucose_random + coronary_artery_disease + haemoglobin+  packed_cell_volume+ peda_edema+ potassium +pus_cell+ pus_cell_clumps + red_blood_cell_count +red_blood_cells +serum_creatinine+ sodium+ specific_gravity,family=binomial(link="logit"),data=data1)
data1 =read.csv( file.choose())
data1
head(data)
model= glm(class ~ Blood_pressure+ aanemia age + appetite+ bacteria+ blood_glucose_random + coronary_artery_disease + haemoglobin+  packed_cell_volume+ peda_edema+ potassium +pus_cell+ pus_cell_clumps + red_blood_cell_count +red_blood_cells +serum_creatinine+ sodium+ specific_gravity,family=binomial(link="logit"),data=data1)
model= glm(class ~ Bloodpressure+ aanemia age + appetite+ bacteria+ bloodglucoserandom + coronaryarterydisease + haemoglobin+  packedcellvolume+ pedaedema+ potassium +puscell+ puscellclumps + redbloodcellcount +redbloodcells +serumcreatinine+ sodium+ specificgravity,family=binomial(link="logit"),data=data1)
data1 =read.csv( file.choose())
data1
head(data)
head(data1)
data1 =read.csv( file.choose())
data1
head(data1)
model= glm(data1$class ~data1$Bloodpressure+ data1$specificgravity + data1$appetite+data1$bacteria+data1$bloodglucose_random + data1$coronaryarterydisease + data1$haemoglobin+  data1$packedcellvolume+ data1$pedaedema+ data1$potassium +data1$puscell+ data1$puscellclumps + data1$redbloodcellcount +data1$redbloodcells +data1$serumcreatinine+ data1$sodium+ data1$specificgravity,family=binomial(link="logit"),data=data1)
summary(model)
data1 =read.csv( file.choose())
head(data1)
model= glm(data1$class ~data1$Bloodpressure+ data1$specificgravity + data1$appetite+data1$bacteria+data1$bloodglucose_random + data1$coronaryarterydisease + data1$haemoglobin+  data1$packedcellvolume+ data1$pedaedema+ data1$potassium +data1$puscell+ data1$puscellclumps + data1$redbloodcellcount +data1$redbloodcells +data1$serumcreatinine+ data1$sodium+ data1$specificgravity,family=binomial(link="logit"),data=data1)
summary(model)
data1 =read.csv( file.choose())
data1
head(data1)
model= glm(data1$class ~data1$Bloodpressure+ data1$specificgravity + data1$appetite+data1$bacteria+data1$bloodglucose_random + data1$coronaryarterydisease + data1$haemoglobin+  data1$packedcellvolume+ data1$pedaedema+ data1$potassium +data1$puscell+ data1$puscellclumps + data1$redbloodcellcount +data1$redbloodcells +data1$serumcreatinine+ data1$sodium+ data1$specificgravity,family=binomial(link="logit"),data=data1)
summary(model)
data1 =read.csv( file.choose())
data1
head(data1)
model= glm(data1$class ~data1$Bloodpressure+ data1$specificgravity + data1$appetite+data1$bacteria+data1$bloodglucose_random + data1$coronaryarterydisease + data1$haemoglobin+  data1$packedcellvolume+ data1$pedaedema+ data1$potassium +data1$puscell+ data1$puscellclumps + data1$redbloodcellcount +data1$redbloodcells +data1$serumcreatinine+ data1$sodium+ data1$specificgravity,family=binomial(link="logit"),data=data1)
summary(model)
options(max.print = 10000)
data1 =read.csv( file.choose(),header = TRUE)
head(data1)
model= glm(data1$y ~data1$x1+ data1$x2 + data1$x3+data1$x4+data1$x5 + data1$x6 + data1$x7+  data1$x8 + data1$x9 + data1$x10 +data1$x11 + data1$x12 + data1$x13 +data1$x14 +data1$x15+ data1$x16+ data1$x17,family=binomial(link="logit"),data=data1)
summary(model)
library(caret)
# Scale the predictor variables
scaled_data <- scale(data1[,2:19])
# Convert the scaled data to a data frame
scaled_data_df <- data.frame(scaled_data)
View(scaled_data_df)
# Add the binary outcome variable to the data frame
scaled_data_df$y <- data1$y
View(scaled_data_df)
#Model with significant variables
logit1<-glm(y~x3+x8+x9+x12,data=scaled_data_df, family = binomial(link = "logit"))
logit1
#Model with significant variables
logit<-glm(y~x3+x8+x9+x12,data=scaled_data_df, family = binomial(link = "logit"))
logit
data1 =read.csv( file.choose())
data1
head(data1)
model= glm(data1$class ~data1$Bloodpressure+ data1$specificgravity + data1$appetite+data1$bacteria+data1$bloodglucose_random + data1$coronaryarterydisease + data1$haemoglobin+  data1$packedcellvolume+ data1$pedaedema+ data1$potassium +data1$puscell+ data1$puscellclumps + data1$redbloodcellcount +data1$redbloodcells +data1$serumcreatinine+ data1$sodium+ data1$specificgravity,family=binomial(link="logit"),data=data1)
summary(model)
a=summary(model)
a
beta=(a$coefficients)[,1]
beta
beta=as.numeric(beta)
beta
# Define a vector with 3 elements
x <- c(10, 4, 15)
# Check the maximum element using if, else if, and else statements
if (x[1] >= x[2] & x[1] >= x[3]) {
print(paste0("The maximum element is ", x[1]))
} else if (x[2] >= x[1] & x[2] >= x[3]) {
print(paste0("The maximum element is ", x[2]))
} else {
print(paste0("The maximum element is ", x[3]))
}
# create a data frame with two groups
df <- data.frame(x = rnorm(20),
y = rep(c("A", "B"), each = 10))
# calculate mean, median, and standard deviation by group
aggregate(df$x, by = list(df$y), FUN = mean) # mean by group
aggregate(df$x, by = list(df$y), FUN = median) # median by group
aggregate(df$x, by = list(df$y), FUN = sd) # standard deviation by group
install.packages("sas7bdat")
install.packages('sas7bdat')
install.packages('sas7bdat')
data1=read_sas7bdat('lond_small.sas7bdat')
library(sas7bdat)
data1=read_sas7bdat('lond_small.sas7bdat')
# import data
data <- read_sas7bdat('lond_small.sas7bdat')
#1 write.table()
data("iris")
view(data)
view(data1)
head(data1)
#now if i want to export the dataset using write.table
write.table(data1,file = 'iris1',sep = ",",na="NA",row.names =FALSE)
#now if i want to export the dataset using write.table
write.table(data1,file = '‪D:\mydata',sep = ",",na="NA",row.names =FALSE)
install.packages("openxlsx")
#2how to read xlsx file
library(openxlsx)
write.xlsx(mpg,dfxlsx.xlsx,row.names=FALSE,keepNA=FALSE)
#2how to read xlsx file
print(x1)
#2how to read xlsx file
print(mpg)
#2how to read xlsx file
data(mpg)
#2how to read xlsx file
data(mtcars)
write.xlsx(mtcars,dfxlsx.xlsx,row.names=FALSE,keepNA=FALSE)
library(xlsx)
install.packages("tableHTML")
#write_tableHtml() will convert a data frame or matrix or any other object that can
#be converted into dataframe
#synatx=write_tableHTML(tableHTML(data.frame),file='file_name')
library(tableHTML)
write_tableHTML(tableHTML(iris),file='df.html')
#check objects in your enviroment
ls()
#remove objects from your enviroment
rm(list=ls())
#check objects in your enviroment
ls()
#Date and time handling in R
Sys.Date()
date()
Sys.time()
d1=as.Date('20Jun2023',format='%d%b%Y')
d1
d1=as.Date('20Jun2023',format='%d%b%y')
d1
d1=as.Date('20Jun2023',format='%d%B%Y')
d1
as.POSIXct(Sys.Date())
install.packages("lubridate")
library(lubridate)
# Create a vector of random numeric values
num_values <- rnorm(10)
# Create a vector of random character values
char_values <- sample(letters, 10, replace=TRUE)
# Create a vector of random logical values
bool_values <- sample(c(TRUE, FALSE), 10, replace=TRUE)
# Create a vector of random factor values
fact_values <- sample(c("A", "B", "C", "D", "E"), 10, replace=TRUE)
# Create a dataframe with the four vectors
df <- data.frame(num_values, char_values, bool_values, fact_values)
# Add some NA values to the dataframe
df$num_values[2] <- NA
df$char_values[5] <- NA
df$bool_values[7] <- NA
df$fact_values[9] <- NA
# Replace all NA values in the character columns with "Empty"
df$char_values[is.na(df$char_values)] <- "Empty"
print(df)
#loading the package into our current session
library(tidyverse)
install.packages("tidyverse")
#loading the package into our current session
library(tidyverse)
mydata=starwars
mydata
print(mydata,width = 150)
mydata=starwars
mydata
#Dateframe
df=mtcars
df
#converting dataframes into tibble
as_tibble(df)
print(as_tibble(df),n=3)
df1 <- data.frame(x = 1:3, y = 3:1)
class(df1[, 1:2])
class(df1[, 1])
df2 <- tibble(x = 1:3, y = 3:1)
class(df2[, 1:2])
class(df2[,1])
names (data.frame('Roll Number'=1))
names (tibble('Roll Number' = 1))
#View the initial ans end values of the data
head(mydata,5) #for first 5 rows of the data
tail(mydata,10)# to view the last 10 values
mydatal<-distinct (mydata,name,.keep_all = TRUE)
##--Select--## to select the column from your data
# Selection using Base R
mydata[c(1,2,3)]
eyes=filter(mydata,eye_color=="blue")
View(eyes)
eyes=filter(mydata,eye_color=="blue")
blue_eyes=filter(mydata,eye_color=="blue" & species=="Human")
View(blue_eyes)
##subset
human=mydata %>% subset(species=="Human")
View(human)
View(human)
human1=mydata %>% subset(species=="Human",select = c(name,eye_color))
View(human1)
##Arrange
#we can do this with [] brackts but it is diffcult to do this #with this but we can do this with arrange very easily.
(mydata[order (mydataSheight),]).
##Arrange
#we can do this with [] brackts but it is diffcult to do this #with this but we can do this with arrange very easily.
(mydata[order (mydataSheight),])
##Arrange
#we can do this with [] brackts but it is diffcult to do this #with this but we can do this with arrange very easily.
(mydata[order (mydata$height),])
View(mydata)
#arrange with pipe
mydata_order <- mydata %% arrange (desc (height))
mydata_order
#arrange with pipe
mydata_order <- mydata %% arrange (desc (height))
#arrange with pipe
mydata_order <- mydata %% arrange(desc(height))
mydata_order
##Arrange
#we can do this with [] brackts but it is diffcult to do this #with this but we can do this with arrange very easily.
(mydata[order (mydata$height),])
#arrange with pipe
mydata_order <- mydata %>% arrange(desc(height))
mydata_order
##Slice
mydata_sliced=mydata %>% slice(c(1,2,3,5))
View(mydata_sliced)
##Rename
#Rename if we want to change the variable name in our dataset
mydata_renamed=mydata %>% rename(weight=mass)
mydata
View(mydata_renamed)
##Relocate
data_relocate=relocate(mydata,sex:homeworld,.before = height)
View(data_relocate)
##Count
mydata_count = mydata %>% count(species)
View(mydata_count)
mydata_group=mydata %>% group_by(homeworld)
View(mydata_group)
#summarise
mydata_grouped=mydata %>% group_by(species) %>% summarise(Avg_height=mean(height,na.rm=T),Avg_mass=mean(mass,na.rm = T))
View(mydata_grouped)
